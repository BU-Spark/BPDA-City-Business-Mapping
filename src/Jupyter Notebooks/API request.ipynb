{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "from pyproj import Proj, transform\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM = geopandas.read_file('Live_Street_Address_Management_SAM_Addresses/Live_Street_Address_Management_SAM_Addresses.shp')\n",
    "# SAM.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAM = pd.read_csv('/Users/naiwenxu/Desktop/BPDA/Live_Street_Address_Management_SAM_Addresses.csv')\n",
    "\n",
    "inProj = Proj(init='epsg:2249')\n",
    "outProj = Proj(init='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google API\n",
    "url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?'\n",
    "loc_url = 'location='\n",
    "rad_url = '&radius=' + '50' + '&key='\n",
    "key = 'AIzaSyBs4j2tThPL0OGgA8bBS3hT-hdq6d8Ch48'\n",
    "\n",
    "responses = {}\n",
    "all_responses = {}\n",
    "\n",
    "for idx in SAM.index[0:12713]: \n",
    "    x = SAM['X'][idx]\n",
    "    y = SAM['Y'][idx]\n",
    "    lng,lat = transform(inProj,outProj,x,y)\n",
    "    add = SAM.iloc[idx]['FULL_ADDRESS']\n",
    "    record = idx\n",
    "    \n",
    "    total_url = url + loc_url + str(lat) + ',' + str(lng) + rad_url + key\n",
    "    response = requests.get(total_url)\n",
    "    x = response.json()\n",
    "    result = x['results']\n",
    "    for j in range(len(result)):\n",
    "        if 'vicinity' in result[j]:\n",
    "            res_addr = result[j]['vicinity'].replace(',', '').replace('.', '').lower().replace(',', \n",
    "                    '').replace('Street', \n",
    "                    'St').replace('Avenue', 'Ave').replace('Terrace', 'Ter').replace('Court', 'Ct').replace('Road', 'Rd').replace('.', '').lower()\n",
    "\n",
    "            real_add = add.replace(',', \n",
    "                    '').replace('Street', \n",
    "                    'St').replace('Avenue', 'Ave').replace('Terrace', 'Ter').replace('Court', 'Ct').replace('Road', 'Rd').replace('.', '').lower()\n",
    "\n",
    "            if res_addr in real_add or real_add in res_addr:\n",
    "                    print(real_add)\n",
    "                    print(res_addr)\n",
    "                    print(result[j]['name'])\n",
    "                    print('*' * 40)\n",
    "                    if add in responses:\n",
    "                        responses[add].append(result[j])\n",
    "                    else:\n",
    "                        responses[add] = [result[j]]\n",
    "            \n",
    "            if add in all_responses:\n",
    "                all_responses[add].append(result[j])\n",
    "            else:\n",
    "                all_responses[add] = [result[j]]\n",
    "                \n",
    "        time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google API cont. - convert the dict type \"all_responses\" to the dataframe\n",
    "df_google = pd.DataFrame()\n",
    "\n",
    "for x in all_responses:\n",
    "    tmp = all_responses[x]\n",
    "    for i in range(len(tmp)):\n",
    "        try:\n",
    "            business_status = tmp[i]['business_status']\n",
    "        except:\n",
    "            business_status = np.nan\n",
    "            \n",
    "        try:\n",
    "            lat = tmp[i]['geometry']['location']['lat']\n",
    "            lon = tmp[i]['geometry']['location']['lng']\n",
    "            viewport = tmp[i]['geometry']['viewport']\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            name = tmp[i]['name']\n",
    "        except:\n",
    "            name = np.nan\n",
    "            \n",
    "        try:\n",
    "            opening_hours = tmp[i]['open_now']\n",
    "        except:\n",
    "            opening_hours = np.nan\n",
    "            \n",
    "        try:\n",
    "            place_id = tmp[i]['place_id']\n",
    "        except:\n",
    "            place_id = np.nan\n",
    "            \n",
    "        try:\n",
    "            price_level = tmp[i]['price_level']\n",
    "        except:\n",
    "            price_level = np.nan\n",
    "            \n",
    "        try:\n",
    "            rating = tmp[i]['rating']\n",
    "        except:\n",
    "            rating = np.nan\n",
    "            \n",
    "        try:\n",
    "            reference = tmp[i]['reference']\n",
    "        except:\n",
    "            reference = np.nan\n",
    "            \n",
    "        try:\n",
    "            types = tmp[i]['types']\n",
    "        except:\n",
    "            types = np.nan\n",
    "            \n",
    "        try:\n",
    "            user_ratings_total = tmp[i]['user_ratings_total']\n",
    "        except:\n",
    "            user_ratings_total = np.nan\n",
    "            \n",
    "        try:\n",
    "            vicinity = tmp[i]['vicinity']\n",
    "            print(vicinity)\n",
    "        except:\n",
    "            vicinity = np.nan\n",
    "            \n",
    "        df_google = df_google.append({'lat': lat, \n",
    "                                      'lon': lon,\n",
    "                                      'vicinity': vicinity,\n",
    "                                      'name': name,\n",
    "                                      'business_status': business_status,\n",
    "                                      'viewport': viewport,\n",
    "                                      'opening_hours': opening_hours,\n",
    "                                      'place_id': place_id,\n",
    "                                      'price_level': price_level,\n",
    "                                      'rating': rating,\n",
    "                                      'reference': reference,\n",
    "                                      'types': types,\n",
    "                                      'user_ratings_total': user_ratings_total,\n",
    "                                       }, \n",
    "                                     ignore_index=True)\n",
    "\n",
    "\n",
    "df_google = df_google.drop_duplicates(keep='first') \n",
    "df_google = df_google.reset_index(drop=True)\n",
    "df_google.to_excel('Google.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bing API\n",
    "BingMapsAPIKey = \"Ag9OGZ8tuL2y_uhT0cKaTg-tuS4wocFWrEmWaIWCcfcMoLC5_2Jma00ZhRVoT0XK\"\n",
    "sequence = ['LAT','LON','ADDRESS_LINE','LOCALITY','ZIP_CODE','FULL_ADDRESS','BUSINESS_NAME','BUSINESS_TYPE','BUSINESS_OTHER_TYPES']\n",
    "\n",
    "df_bing = pd.DataFrame()\n",
    "\n",
    "for idx in SAM.index[0:398461]: \n",
    "    x = SAM['X'][idx]\n",
    "    y = SAM['Y'][idx]\n",
    "    longitude,latitude = transform(inProj,outProj,x,y)\n",
    "    record = idx\n",
    "\n",
    "    search_url = \"http://dev.virtualearth.net/REST/v1/locationrecog/\" + str(latitude) + \",\" + str(longitude) +\\\n",
    "                    \"?key=\" + BingMapsAPIKey + \"&output=json\"\n",
    "    response = requests.get(search_url)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "\n",
    "    for i in range(len(search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'])):\n",
    "        try:\n",
    "            lat = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessAddress']['latitude']\n",
    "            lon = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessAddress']['longitude']\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            addressLine = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessAddress']['addressLine']\n",
    "        except:\n",
    "            addressLine = np.nan\n",
    "            \n",
    "        try:\n",
    "            locality = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessAddress']['locality']\n",
    "        except:\n",
    "            locality = np.nan\n",
    "            \n",
    "        try:\n",
    "            postalCode = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessAddress']['postalCode']\n",
    "        except:\n",
    "            postalCode = np.nan\n",
    "            \n",
    "        try:\n",
    "            formattedAddress = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessAddress']['formattedAddress']\n",
    "        except:\n",
    "            formattedAddress = np.nan           \n",
    "        \n",
    "        try:\n",
    "            entityName = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessInfo']['entityName']\n",
    "        except:\n",
    "            entityName = np.nan\n",
    "            \n",
    "        try:\n",
    "            entityType = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessInfo']['type']\n",
    "        except:\n",
    "            entityType = np.nan\n",
    "            \n",
    "        try:\n",
    "            otherTypes = search_results['resourceSets'][0]['resources'][0]['businessesAtLocation'][i]['businessInfo']['otherTypes']\n",
    "        except:\n",
    "            otherTypes = np.nan\n",
    "        \n",
    "        df_bing = df_bing.append({'LAT': lat, \n",
    "                                  'LON': lon,\n",
    "                                  'ADDRESS_LINE': addressLine,\n",
    "                                  'LOCALITY': locality,\n",
    "                                  'ZIP_CODE': postalCode,\n",
    "                                  'FULL_ADDRESS': formattedAddress,\n",
    "                                  'BUSINESS_NAME': entityName,\n",
    "                                  'BUSINESS_TYPE': entityType,\n",
    "                                  'BUSINESS_OTHER_TYPES': otherTypes\n",
    "                                   }, \n",
    "                                 ignore_index=True)\n",
    "        \n",
    "\n",
    "df_bing = df_bing.drop_duplicates(subset=['LAT','LON','FULL_ADDRESS','BUSINESS_NAME'], keep='first')\n",
    "df_bing = df_bing.reset_index(drop=True)\n",
    "df_bing = df_bing.reindex(columns=sequence)\n",
    "df_bing.to_excel('Bing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yelp API\n",
    "api_key = \"eh3zFdgSVMfj4I8Rifh_FlfB1YzKdVyHrDe3koTnxy9WQAjhULg5Iwwfv7PBvk4i27snFzk5QM45EfvfiyyfQh-9t2eNNCO1q9YD3T_O88GmX84FNDjr0_4kJV6QX3Yx\"\n",
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "sequence = ['id','latitude','longitude','street_address','locality','business_name','categories','is_closed',\n",
    "            'phone', 'rating']\n",
    "\n",
    "df_yelp = pd.DataFrame()\n",
    "Google = pd.read_excel('/Users/naiwenxu/Desktop/Google.xlsx')\n",
    "\n",
    "for idx in Google.index[0:38918]: \n",
    "    lat = Google['lat'][idx]\n",
    "    lon = Google['lon'][idx]\n",
    "    term = Google['name'][idx]\n",
    "    record = idx\n",
    "    \n",
    "    url_params = {'term': term,\n",
    "                  'latitude': lat,\n",
    "                  'longitude': lon,\n",
    "                  'radius': 50}\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    search_results = response.json()\n",
    "    search_results\n",
    "    \n",
    "    for i in range(len(search_results['businesses'])):\n",
    "        businessID = search_results['businesses'][i]['id']\n",
    "        latitude = search_results['businesses'][i]['coordinates']['latitude']\n",
    "        longitude = search_results['businesses'][i]['coordinates']['longitude']\n",
    "        businessName = search_results['businesses'][i]['name']\n",
    "\n",
    "        if len(search_results['businesses'][i]['location']['display_address']) > 1:\n",
    "            address1 = search_results['businesses'][i]['location']['display_address'][0]\n",
    "            address2 = search_results['businesses'][i]['location']['display_address'][1]\n",
    "            street_address = address1\n",
    "            locality = address2\n",
    "        else:\n",
    "            address = search_results['businesses'][i]['location']['display_address'][0]\n",
    "            locality = address\n",
    "\n",
    "        categories = []\n",
    "        for j in range(len(search_results['businesses'][i]['categories'])):\n",
    "            categories.append(search_results['businesses'][i]['categories'][j]['title'])\n",
    "\n",
    "        try:\n",
    "            is_closed = search_results['businesses'][i]['is_closed']\n",
    "        except:\n",
    "            is_closed = np.nan\n",
    "\n",
    "        try:\n",
    "            rating = search_results['businesses'][i]['rating']\n",
    "        except:\n",
    "            rating = np.nan\n",
    "\n",
    "        try:\n",
    "            phone = search_results['businesses'][i]['display_phone']\n",
    "        except:\n",
    "            phone = np.nan\n",
    "            \n",
    "        try:\n",
    "            review_count = search_results['businesses'][i]['review_count']\n",
    "        except:\n",
    "            review_count = np.nan\n",
    "            \n",
    "        try:\n",
    "            price = search_results['businesses'][i]['price']\n",
    "        except:\n",
    "            price = np.nan\n",
    "\n",
    "        df_yelp = df_yelp.append({'id': businessID,\n",
    "                                  'latitude': latitude, \n",
    "                                  'longitude': longitude,\n",
    "                                  'street_address': street_address,\n",
    "                                  'locality': locality,\n",
    "                                  'business_name': businessName,\n",
    "                                  'categories': categories,\n",
    "                                  'is_closed': is_closed,\n",
    "                                  'phone': phone,\n",
    "                                  'rating': rating,\n",
    "                                  'review_count': review_count,\n",
    "                                  'price': price},\n",
    "                                  ignore_index=True)\n",
    "        \n",
    "df_yelp = df_yelp.drop_duplicates(keep='first')\n",
    "df_yelp = df_yelp.reset_index(drop=True)\n",
    "df_yelp = df_yelp.reindex(columns=sequence)\n",
    "df_yelp.to_excel('Yelp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenStreetMaps API\n",
    "sequence = ['osm_id','latitude','longitude','business_name','road','neighbourhood','suburb','city','county',\n",
    "            'state','postcode','full_address']\n",
    "df_OSM = pd.DataFrame()\n",
    "coord = pd.read_excel('coord.xlsx')\n",
    "\n",
    "for idx in coord.index[0:7625]: \n",
    "    lat = coord['LAT'][idx]\n",
    "    lon = coord['LON'][idx]\n",
    "    record = idx\n",
    "    \n",
    "    search_url = \"https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat=\" + str(lat) + \"&lon=\" + str(lon)\n",
    "    response = requests.get(search_url)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    \n",
    "    for i in range(len(search_results)):\n",
    "        try:\n",
    "            osm_id = search_results['osm_id']\n",
    "            latitude = search_results['lat']\n",
    "            longitude = search_results['lon']\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            name = search_results['address']['amenity']\n",
    "        except:\n",
    "            name = ''\n",
    "            \n",
    "        try:\n",
    "            road = search_results['address']['road']\n",
    "        except:\n",
    "            road = ''\n",
    "            \n",
    "        try:\n",
    "            neighbourhood = search_results['address']['neighbourhood']\n",
    "        except:\n",
    "            neighbourhood = ''\n",
    "            \n",
    "        try:\n",
    "            suburb = search_results['address']['suburb']\n",
    "        except:\n",
    "            suburb = ''\n",
    "            \n",
    "        try:\n",
    "            city = search_results['address']['city']\n",
    "        except:\n",
    "            city = ''\n",
    "            \n",
    "        try:\n",
    "            county = search_results['address']['county']\n",
    "        except:\n",
    "            county = ''\n",
    "            \n",
    "        try:\n",
    "            state = search_results['address']['state']\n",
    "        except:\n",
    "            state = ''\n",
    "            \n",
    "        try:\n",
    "            postcode = search_results['address']['postcode']\n",
    "        except:\n",
    "            postcode = ''\n",
    "    \n",
    "        address = road + ', ' + neighbourhood + ', ' + suburb + ', ' + city + ', ' + \\\n",
    "                  county + ', ' + state + ', ' + postcode\n",
    "        \n",
    "    df_OSM = df_OSM.append({'osm_id': osm_id,\n",
    "                            'latitude': latitude, \n",
    "                            'longitude': longitude,\n",
    "                            'business_name': name,\n",
    "                            'road': road,\n",
    "                            'neighbourhood': neighbourhood,\n",
    "                            'suburb': suburb,\n",
    "                            'city': city,\n",
    "                            'county': county,\n",
    "                            'state': state,\n",
    "                            'postcode': postcode,\n",
    "                            'full_address': address},\n",
    "                            ignore_index=True)\n",
    "    \n",
    "df_OSM = df_OSM.drop_duplicates(subset=['business_name', 'full_address'], keep='first')\n",
    "df_OSM = df_OSM.reset_index(drop=True)\n",
    "df_OSM = df_OSM.reindex(columns=sequence)\n",
    "df_OSM.to_excel('OSM.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "f = pd.read_excel('merged_list_no_residential.xlsx')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yellowpages = f[(f['In Yellowpages list (Y/N)'] == 'Y')]\n",
    "len(Yellowpages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bing = f[(f['In Bing list (Y/N)'] == 'Y')]\n",
    "len(Bing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google = f[f['In Google list (Y/N)'] == 'Y']\n",
    "len(Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SafeGraph = f[(f['In SafeGraph list (Y/N)'] == 'Y')]\n",
    "len(SafeGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yelp = f[(f['In Yelp list (Y/N)'] == 'Y')]\n",
    "len(Yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfoUSA = f[(f['In InfoUSA list (Y/N)'] == 'Y')]\n",
    "len(InfoUSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manual_Google = f[f['In Manual Searching (Y/N)'] == 'Y']\n",
    "len(Manual_Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combo1 - Google Places API + Bing + Yelp + Yellowpages\n",
    "Combo1 = f[(f['In Bing list (Y/N)'] == 'Y') |\n",
    "           (f['In Yelp list (Y/N)'] == 'Y') |\n",
    "           (f['In Yellowpages list (Y/N)'] == 'Y') |\n",
    "           (f['In Google list (Y/N)'] == 'Y')]\n",
    "\n",
    "len(Combo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combo2 - Safegraph + Bing + Yelp + Yellowpages\n",
    "Combo2 = f[(f['In Bing list (Y/N)'] == 'Y') |\n",
    "           (f['In Yelp list (Y/N)'] == 'Y') |\n",
    "           (f['In Yellowpages list (Y/N)'] == 'Y') |\n",
    "           (f['In SafeGraph list (Y/N)'] == 'Y')]\n",
    "\n",
    "len(Combo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newf = f[f['In Manual Google (Y/N)'] == 'Y']\n",
    "\n",
    "x = newf[(newf['In Bing list (Y/N)'] == 'Y') |\n",
    "         (newf['In Yelp list (Y/N)'] == 'Y') |\n",
    "         (newf['In Yellowpages list (Y/N)'] == 'Y') |\n",
    "         (newf['In SafeGraph list (Y/N)'] == 'Y') |\n",
    "         (newf['In Google list (Y/N)'] == 'Y')]\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newf = f[f['In MSD list (Y/N)'] == 'Y']\n",
    "\n",
    "x = newf[(newf['In Bing list (Y/N)'] == 'Y') |\n",
    "         (newf['In Yelp list (Y/N)'] == 'Y') |\n",
    "         (newf['In Yellowpages list (Y/N)'] == 'Y') |\n",
    "         (newf['In SafeGraph list (Y/N)'] == 'Y') |\n",
    "         (newf['In Google list (Y/N)'] == 'Y')]\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newf = f[f['In InfoUSA list (Y/N)'] == 'Y']\n",
    "\n",
    "x = newf[(newf['In SafeGraph list (Y/N)'] =='Y') |\n",
    "         (newf['In Bing list (Y/N)'] == 'Y') |\n",
    "         (newf['In Yelp list (Y/N)'] == 'Y') |\n",
    "         (newf['In Yellowpages list (Y/N)'] == 'Y')]\n",
    "\n",
    "len(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
